DataPlane-ML: Uma Solução Integrada de Detecção e Mitigação de Ataques para Redes Definidas por Software

Resumo
As Redes Definidas por Software (SDN) são um paradigma que enfatiza a separação do plano de controle do plano de dados, oferecendo vantagens como flexibilidade e programabilidade. No entanto, do ponto de vista da segurança, as SDN também introduzem novas vulnerabilidades devido à comunicação necessária entre esses planos. Os ataques de SYN Flood são típicos ataques de negação de serviço distribuído (DDoS) que desafiam especialmente os administradores de rede, pois produzem um grande volume de conexões TCP semiabertas para um alvo, comprometendo sua disponibilidade. A maioria das soluções atuais para detectar e mitigar esses ataques é projetada para operar no plano de controle, impondo uma sobrecarga adicional às funções do controlador. Além disso, os mecanismos de bloqueio de tráfego, uma alternativa amplamente utilizada para proteger os recursos da rede, têm a desvantagem de restringir o tráfego legítimo. Este trabalho propõe o DataPlane-ML, uma solução integrada para detectar e mitigar ataques DDoS em SDN, atuando diretamente no plano de dados. O DataPlane-ML utiliza técnicas de aprendizado de máquina para detecção de ataques e uma solução de mitigação baseada na reputação do nó para evitar o bloqueio de tráfego legítimo durante um ataque. Os resultados experimentais mostram que o DataPlane-ML é ≈26% mais rápido que as soluções baseadas em estatísticas para detecção de ataques, apresentando maior precisão. Além disso, a solução de mitigação do DataPlane-ML pode preservar mais de 95% do tráfego legítimo durante um ataque.

1. INTRODUÇÃO

As Redes Definidas por Software (SDN) surgiram como um novo paradigma de rede que desacopla o plano de dados do plano de controle. O plano de dados é responsável por ações de encaminhamento e roteamento, utilizando dispositivos como switches e roteadores. Por outro lado, um controlador baseado em software (plano de controle) é responsável por coordenar a gestão de recursos e políticas da rede. A comunicação entre os dois planos utiliza protocolos padrão, como o OpenFlow. A arquitetura SDN também define um plano de aplicação que executa aplicações de rede para ajudar o controlador a configurar a rede. Essa arquitetura torna a rede flexível, ou seja, o administrador da rede pode aprimorar o controlador com novas funcionalidades, incluindo funções de segurança.

Apesar desses benefícios, a segurança ainda é uma preocupação importante nas SDN, pois a separação entre os planos aumenta a superfície de ataque. Os ataques de negação de serviço distribuído (DDoS) são particularmente desafiadores, pois visam esgotar os recursos da rede, geralmente enviando um grande volume de tráfego de diferentes locais para o alvo do ataque. Na arquitetura SDN, o controlador é um alvo atraente para ataques, pois sua disfunção pode potencialmente interromper a rede. Nesse caso, o principal objetivo dos ataques DDoS é sobrecarregar o controlador para limitar sua capacidade de lidar com o tráfego legítimo da rede.

Os ataques DDoS podem ser classificados em dois grupos principais: ataques volumétricos e ataques não volumétricos (de baixo volume ou baixa taxa). Neste trabalho, restringimos nossa atenção aos ataques volumétricos de SYN Flood, que consistem no envio de numerosas solicitações de conexão TCP, usando endereços de origem falsos, na forma de segmentos SYN para o servidor. O servidor responde a cada mensagem recebida com um SYN-ACK e aguarda o segmento ACK para estabelecer a conexão. Como o endereço de origem do pacote SYN foi forjado, a resposta ACK nunca chegará, fazendo com que a conexão permaneça em um estado semiaberto, consumindo recursos do controlador. Consequentemente, a fila de conexões TCP enche, sobrecarregando o controlador e impedindo que ele responda a solicitações legítimas de clientes TCP.

Métodos estatísticos e de aprendizado de máquina (ML) para detecção de ataques DDoS têm sido usados para classificar tráfego legítimo e fraudulento em SDN. Em geral, essas soluções usam dados coletados no plano de dados (ou seja, informações de fluxos de tráfego) e tentam descobrir se um determinado fluxo está relacionado a um ataque. Um fluxo pode ser definido como uma sequência de pacotes de um nó de origem para um destino, que pode ser outro nó, um grupo de multicast ou um domínio de broadcast. Normalmente, os protocolos para detectar ataques DDoS são executados no plano de controle. Portanto, o controlador precisa manter uma comunicação contínua com os switches do plano de dados para obter informações da rede. Assim, embora o controlador facilite a gestão automatizada da rede e torne mais fácil integrar e administrar aplicações, o desenvolvimento de soluções de segurança no plano de controle é um fardo adicional para o controlador. Diante dessas preocupações, técnicas de segurança SDN implementadas diretamente no plano de dados têm sido consideradas na literatura. Por exemplo, em [9], foi proposto um mecanismo de detecção de ataques DDoS baseado em entropia (técnica estatística) para atuar no plano de dados. Além disso, as soluções no plano de dados são capazes de detectar ataques DDoS mais rapidamente do que as soluções implementadas no controlador.

Em comparação com técnicas estatísticas, as alternativas de ML têm sido amplamente adotadas para detectar ataques em redes SDN. Embora as técnicas de ML geralmente apresentem maior precisão na detecção de ataques, elas ainda não foram implementadas no plano de dados. No entanto, para implementar soluções de segurança no plano de dados, é preciso lidar com as limitações dos dispositivos do plano de dados, como a necessidade de personalizar o hardware ou um protocolo de comunicação específico. Para esse fim, este trabalho recorre ao uso do Programming Protocol-independent Packet Processors (P4), que é uma linguagem específica de domínio para dispositivos de rede que especifica como os dispositivos do plano de dados (por exemplo, switches, NICs, roteadores, filtros) processam os pacotes. Essa linguagem tem promovido o desenvolvimento de soluções no plano de dados com resultados promissores. No entanto, o P4 não pode lidar com cálculos de ponto flutuante. Para superar essas limitações, o Apache Thrift é usado para permitir a comunicação entre diferentes aplicações via RPC (chamadas de procedimento remoto). Ou seja, as funcionalidades do P4 são usadas para lidar com o tráfego, e o Apache Thrift é usado para se comunicar com os procedimentos de ML e estatísticas no plano de dados. Essa estratégia permite o uso de técnicas de ML no plano de dados para fornecer soluções mais elaboradas que operam próximas ao fluxo de entrada sem impactar o controlador SDN. Além disso, o P4 pode ser implementado em cima de switches de caixa branca executando chips comerciais, o que permite a programabilidade da rede sem estar vinculado a um fabricante de hardware específico. Em caso de ataque, uma eventual sobrecarga do switch do plano de dados não comprometeria os recursos do controlador, reduzindo a área de superfície de ataque. Também investigamos o impacto no mecanismo de detecção de ataques causado por diferentes parâmetros, como tempo de observação e volume de pacotes.

Tentando minimizar os efeitos causados por ataques DDoS, propusemos um mecanismo de mitigação baseado na reputação dos nós, que também é executado no plano de dados. Um trabalho anterior propôs o DoSSec para mitigar esses ataques monitorando os fluxos e classificando-os em diferentes listas de prioridade. Quando um ataque é detectado, os fluxos são bloqueados com base na lista à qual pertencem. Este trabalho estende e combina nossos trabalhos publicados anteriormente, que apareceram em [17, 18], usando uma solução mais evoluída com algoritmos de reputação, prioridade de nós e mecanismo de detecção de ML aplicado ao plano de dados SDN. Até onde sabemos, este é o primeiro trabalho a aplicar técnicas de ML para detecção de ataques e mecanismos de mitigação de ataques diretamente no plano de dados. Além disso, como uma contribuição adicional, apresentamos uma avaliação experimental extensiva do DataPlane-ML, considerando diferentes parâmetros e métricas, como tempo para detectar um ataque e uso da CPU. Os resultados de detecção de ataques do DataPlane-ML são comparados com abordagens estatísticas tradicionais. Os resultados experimentais mostram que as técnicas de ML podem detectar ataques mais rapidamente (≈26%) e com maior precisão do que soluções baseadas em entropia. Além disso, o mecanismo de mitigação baseado na reputação dos nós pode preservar o tráfego legítimo com uma precisão de mais de 95% durante um ataque, mostrando-se capaz de identificar nós maliciosos na rede.

Em resumo, as principais contribuições deste artigo são:

    Uma solução no plano de dados para detectar ataques de SYN Flood usando técnicas de ML;

    Um mecanismo de mitigação baseado na reputação dos nós para minimizar os efeitos causados por esses ataques;

    Uma solução integrada de detecção e mitigação de ataques projetada para SDN.

O restante deste artigo está organizado da seguinte forma. A Seção 2 apresenta o contexto deste trabalho, considerando redes definidas por software, ataques de SYN Flood, algoritmos de detecção e técnicas de mitigação. A Seção 3 revisa trabalhos relacionados. A Seção 4 discute a solução que usamos para estabelecer a reputação de cada nó. A Seção 5 descreve a solução DataPlane-ML. A Seção 6 mostra a avaliação de desempenho do DataPlane-ML. Finalmente, a Seção 7 conclui o artigo.

2. CONTEXTO SOBRE SDN E ATAQUES DDOS SYN FLOOD

Esta seção começa com uma visão geral e definições relacionadas a redes definidas por software e ataques de SYN Flood. Em seguida, é apresentada uma breve visão dos métodos frequentemente empregados para detectar e mitigar ataques DDoS em SDN. Métodos estatísticos e baseados em aprendizado de máquina (ML) são comumente usados para identificar desvios no tráfego da rede que podem caracterizar um ataque. Os métodos de mitigação incluem ações como bloqueio de tráfego, controle de conexão e gerenciamento de recursos, na tentativa de atenuar os efeitos do ataque na rede.

2.1 Redes Definidas por Software (SDN)

Esta seção apresenta algumas características essenciais da arquitetura de redes definidas por software (SDN), que é dividida em três planos:

    Plano de Dados: este plano contém os dispositivos de rede responsáveis por ações de encaminhamento e roteamento (por exemplo, switches e roteadores), bem como pelo monitoramento de informações locais e coleta de estatísticas. Esses dispositivos são configurados com um conjunto de regras de fluxo usadas para redirecionar pacotes de entrada pertencentes a um fluxo. Um fluxo é definido como uma sequência de pacotes de um endereço de nó de origem para um nó de destino (unicast) ou nós (multicast).

    Plano de Controle: este plano contém um controlador que gerencia toda a rede, configurando o plano de dados (por exemplo, switches), sendo responsável por criar e coordenar as funcionalidades dos dispositivos de rede. Ele se comunica com o plano de dados por uma interface sul (southbound) usando protocolos padrão, como o OpenFlow.

    Plano de Aplicação: este plano compreende um conjunto de aplicações de rede (por exemplo, balanceador de carga e serviços de QoS) que ajudam o controlador. Ele se comunica com o plano de controle por meio da interface norte (northbound), que fornece uma plataforma para o desenvolvimento de aplicações de rede.

A Figura 1 mostra os elementos da SDN, representando os planos de aplicação, controle e dados, bem como as interfaces norte e sul. O desacoplamento entre a implementação da lógica de controle da rede e as operações de encaminhamento promove maior flexibilidade no controle e gerenciamento da rede. Além disso, avanços recentes em planos de dados programáveis (PDP) permitiram que os administradores de rede redefinissem o comportamento dos dispositivos do plano de dados (switches), trazendo ainda mais flexibilidade e facilitando o desenvolvimento de novos protocolos de rede. O PDP é geralmente composto por switches P4 que podem interagir com os pacotes de entrada usando a linguagem P4. Este trabalho explora esse aspecto e propõe um mecanismo de detecção de ataques baseado em ML e um mecanismo de mitigação baseado em reputação que é executado no plano de dados, evitando assim a comunicação com um controlador potencialmente sobrecarregado.

2.2 Conexão TCP e Ataques DDoS SYN Flood

O estabelecimento de uma conexão TCP é baseado no conhecido handshake de três vias. O handshake implica a troca de segmentos TCP com flags especiais entre o cliente e o servidor. A troca desses segmentos TCP é realizada em três etapas: (1) o cliente envia um segmento TCP com a flag SYN definida para o servidor; (2) ao receber o SYN TCP, o servidor responde ao cliente com um segmento TCP com a flag SYN-ACK ativada; (3) o cliente envia um segmento TCP com a flag ACK ativada, e a conexão é estabelecida. A conexão eventualmente termina com um RST (reset ou encerramento) ou FIN (encerramento gracioso da conexão).

O ataque de SYN Flood abusa do handshake de três vias do TCP para esgotar os recursos da vítima. O atacante usa endereços de origem falsos no segmento SYN. Consequentemente, o servidor aloca e inicializa variáveis de conexão e buffers e responde com um SYN-ACK para um endereço falso, aguardando a resposta ACK para estabelecer a conexão. Como o ACK não é recebido, a conexão permanece em um estado semiaberto (SYN-RECV) no servidor, ou seja, permanece na fila de conexões TCP do servidor. Com inúmeras conexões semiabertas, o atacante pode sobrecarregar todas as filas de conexões TCP disponíveis em uma máquina servidora alvo, sobrecarregando o servidor, que eventualmente não conseguirá responder a solicitações legítimas de clientes TCP.

2.3 Algoritmos de Detecção de Ataques DDoS

Os ataques de negação de serviço distribuído (DDoS) visam esgotar os recursos de dispositivos ou infraestruturas para causar indisponibilidade de serviços. Os métodos de detecção de ataques DDoS podem ser classificados por meio de algoritmos de classificação de dados. Eles podem ser categorizados em métodos baseados em algoritmos estatísticos e algoritmos de aprendizado de máquina (ML). Os algoritmos estatísticos realizam análises de várias propriedades do tráfego em ambas as fases: com e sem tráfego fraudulento. Essas propriedades são usadas para criar um modelo de referência para identificar desvios comportamentais. Entropia, φ-Entropia e Chi-Square são métodos estatísticos comumente usados para detectar anomalias no tráfego da rede.

Os algoritmos de ML são treinados para entender o comportamento do tráfego da rede, aprendendo a partir de dados históricos, para identificar possíveis ameaças. Restringimos nossa atenção a técnicas de aprendizado supervisionado que são discutidas na revisão da literatura apresentada na seção subsequente. O algoritmo K-Nearest Neighbors (KNN) tem sido amplamente empregado para detectar anomalias na rede. O algoritmo funciona procurando os k-vizinhos mais próximos com base na distância entre pontos presentes em um espaço dimensional. A complexidade computacional do KNN é proporcional ao tamanho do conjunto de dados de treinamento para cada amostra de teste. O KNN é executado em tempo O(nd), onde n é o número de amostras e d é o número de dimensões. Da mesma forma, o algoritmo Support Vector Machine (SVM) tem ganhado atenção crescente ultimamente. O algoritmo SVM procura por um hiperplano que melhor separa os dados de cada classe, maximizando a margem de separação. Para encontrar um hiperplano adequado, o algoritmo é executado em tempo O(n³), onde n é o número de amostras. Random Forest (RF) é outra técnica de ML amplamente empregada para detectar ataques de rede. O RF consiste em uma coleção de classificadores estruturados em uma árvore de decisão, onde o resultado da classificação é a classe com o maior número de votos entre as árvores presentes na floresta para uma determinada seleção de amostras aleatórias. O RF é executado em tempo O(mkn log n), onde m é o número de árvores aleatórias, n é o número de amostras e k ≪ m é o número de variáveis sorteadas aleatoriamente em cada nó para construir as árvores aleatórias.

2.4 Técnicas de Mitigação de Ataques DDoS

Os mecanismos de defesa contra ataques DDoS em SDN incluem diferentes técnicas de mitigação. As técnicas de mitigação podem ser categorizadas em três classes: (i) bloqueio (ou descarte); (ii) controle; e (iii) gerenciamento de recursos. Cada técnica tem vantagens e desvantagens associadas, variando desde uma aplicação mais severa, como o bloqueio de todo o tráfego, até um controle mais refinado, que busca preservar um maior volume de tráfego legítimo na rede.

As classes de bloqueio e descarte são as técnicas de mitigação mais simples e rápidas, que bloqueiam completamente possíveis fontes de ataque. Essa técnica fornece mitigação imediata aos recursos da rede. No entanto, se um nó legítimo (host) ou porta for comprometido, ele será completamente bloqueado, resultando no descarte de qualquer tráfego legítimo dessas fontes. Dessa forma, é necessário ter um sistema de detecção de intrusão capaz de reduzir as taxas de falsos positivos para manter a conectividade da rede para usuários legítimos. A classe de controle visa atrasar, ou seja, redirecionar o tráfego fraudulento, reduzindo a largura de banda ou o número de mensagens enviadas ao controlador quando um ataque é detectado. Essa técnica é mais complexa que o bloqueio, aumenta o tempo de processamento e o tráfego da rede, mas nós ou tráfegos legítimos declarados maliciosos pelo sistema de detecção ainda têm a chance de se comunicar com a rede. Por outro lado, o atacante continuará a consumir alguns recursos da rede, pois não é imediatamente bloqueado pela solução. Finalmente, a classe de gerenciamento de recursos configura e gerencia a rede por meio de recursos adicionais presentes na infraestrutura. Assim, as soluções usam mecanismos auxiliares, como IDS (Sistema de Detecção de Intrusão), CICFlowMeter e sFlow-RT. No entanto, com o uso desse tipo de técnica, as soluções podem ser limitadas aos recursos disponíveis na infraestrutura para a implementação do mecanismo proposto.

3. TRABALHOS RELACIONADOS

Como discutido na seção anterior, o uso de técnicas de aprendizado de máquina (ML) para detecção e métodos como bloqueio, controle ou gerenciamento de recursos para mitigação de anomalias na rede tem ganhado atenção crescente nos últimos anos. À medida que as redes definidas por software amadurecem e se tornam mais populares, as preocupações com segurança ainda desafiam os operadores de rede, incentivando o desenvolvimento de soluções específicas para SDN. Esta subseção discute trabalhos relacionados, com foco na mitigação de DDoS e detecção de ataques, em particular os ataques de SYN Flood em SDN.

Um método para detectar ataques DDoS usando algoritmos baseados em SVM foi proposto em [8]. O método opera no plano de controle e usa as informações de fluxo disponíveis para o controlador para aprender e classificar o tráfego em tráfego normal e fraudulento. Obaid et al. [40] propuseram uma abordagem semelhante, empregando diferentes algoritmos de ML, como RF, J48 e KNN. Deepa et al. [41] propuseram uma abordagem que combina diferentes algoritmos de ML (KNN, SVM e Self-Organizing Maps - SOM) para realizar a classificação do tráfego de ataque. Na mesma linha, Tuan et al. [42] propuseram o uso de diferentes abordagens, combinando entropia com KNN para detectar ataques DDoS. Da mesma forma, os autores em [43] propuseram uma solução que permite combinar entropia com diferentes algoritmos de ML, como Multi-Layer Perceptron (MLP), KNN e SVM. Em [44], os autores propuseram uma solução para detectar anomalias de ataques DDoS usando NIDS (Sistema de Detecção de Intrusão de Rede) em um ambiente SDN. Diferentes classificadores de ML (RF, SVM, Regressão Logística (LR) e KNN) foram empregados. O impacto de diferentes janelas de observação no desempenho de detecção de três algoritmos de classificação (SVM, Naive Bayes e KNN) foi avaliado por Samer et al. [45].

Os trabalhos a seguir buscam reduzir os impactos causados pelo ataque de SYN Flood. O Avant-Guard é proposto em [12]. A ideia é transformar o switch em um proxy. A proposta intercepta informações de conexão TCP em uma sessão e encaminha apenas solicitações completas para o controlador. Como efeito colateral, a solução aumenta o atraso causado no estabelecimento de conexões legítimas devido ao proxy. Isso permite que hosts atacantes com IPs já validados continuem atacando. Semelhante ao Avant-Guard [12], a solução proposta em [31] transforma o controlador em um proxy, que sempre rejeita a primeira conexão do cliente. A solução mantém um contador de solicitações SYN, e se o número de solicitações SYN exceder o limite, o controlador realiza a ação de bloqueio do atacante. Embora a solução seja eficiente, se o atacante completar o primeiro handshake TCP, ele não terá mais obstáculos para atacar a vítima. Kumar et al. [32] propuseram uma solução que usa entropia como mecanismo de detecção. A análise é baseada no IP de destino dos pacotes para detectar anomalias e identificar a fonte do ataque. A mitigação envolve descobrir a fonte maliciosa e bloqueá-la na porta do switch. Embora a solução seja eficaz, o bloqueio da porta do switch pode penalizar todos os fluxos legítimos vinculados a essa porta. Kim et al. propuseram detectar o ataque usando o mecanismo TCP Time Out e Round Trip Time (RTT) [33]. A solução descarta o primeiro pacote SYN de qualquer host e estima o tempo de espera com base no tempo entre o primeiro e o segundo pacote SYN, removendo as sessões TCP semiabertas após o tempo de espera. Se o RTT do ACK for menor que o RTT observado, o pacote ACK é encaminhado para o servidor; caso contrário, é descartado pela solução [33]. Embora a solução seja eficaz, ter um RTT muito curto pode penalizar hosts legítimos que têm dificuldade em completar uma conexão.

Em [36], os autores propuseram uma metodologia para detectar o ataque de SYN Flood comparando a contagem de SYN (extraída do analisador sFlow-RT) com um limite adaptativo, que é calculado usando EWMA (média móvel exponencialmente ponderada). Quando o ataque é detectado, uma regra é aplicada para descartar os fluxos no switch de origem do ataque. Embora a solução seja eficiente na detecção, ela não mostra como os fluxos legítimos e fraudulentos são distinguidos, o que pode gerar muitos falsos positivos. Os autores em [37] propuseram uma solução baseada em dois componentes: (i) o monitor; e (ii) o correlator. O primeiro recebe alertas de um IDS e sintetiza informações relacionadas ao ataque e as envia para o correlator. O segundo opera no controlador e verifica as informações recebidas do monitor, analisando as informações de fluxo de entrada. Após confirmar a existência de um ataque, o processo de mitigação é realizado para bloquear o IP e a porta do atacante e descartar o tráfego de ataque. Embora a solução seja eficiente, o bloqueio de portas pode penalizar fluxos legítimos.

Lin et al. [34] propuseram uma estratégia simples de detecção e bloqueio. Para detecção, os autores analisaram a proporção entre pacotes SYN/ACK e ACK/FIN. Assim, se a proporção entre esses pacotes não corresponder, há uma indicação de tráfego anômalo na rede. A estratégia de bloqueio visa limitar e descartar o tráfego do atacante de acordo com uma faixa de IP que está mais próxima do atacante considerado suspeito, de acordo com a classe do endereço IP (por exemplo, A, B e C). Embora a solução limite o tráfego de ataque, ela pode penalizar o tráfego legítimo se nenhuma regra de priorização for aplicada. Os autores em [35] propuseram uma solução semelhante à de Lin et al. [34]. A solução aplica um limite de taxa dinâmico para o número de pacotes enviados ao controlador. Em seguida, coleta estatísticas de fluxo dos switches, com base na taxa de pacotes e bytes, para medir e controlar a taxa de pacotes enviados ao controlador e definir o limite de detecção. Quando esse limite é excedido, o switch reduz o número de fluxos enviados ao controlador. Embora a solução realize o controle dos fluxos enviados ao controlador, ela não distingue o tipo de fluxo a ser atrasado.

Os autores em [46] analisaram a confiabilidade de aplicações SDN por meio de reputação. A reputação é estabelecida por meio de uma distribuição beta, concedendo um crédito. O principal fator para atribuir a reputação é o feedback do controlador em relação à solicitação do cliente. Em [47], os autores usaram reputação para avaliar aplicações externas. A solução leva em consideração dados históricos para estabelecer uma reputação. Fluxos com boa reputação têm maior prioridade para serem atendidos. As soluções apresentadas não exploram os riscos relacionados a ataques DDoS, mas mostram como o conceito de reputação pode ser usado em uma rede SDN.

Observa-se que a maioria das soluções de detecção foi projetada para funcionar no plano de controle, o que aumenta as responsabilidades do controlador e a latência de comunicação para coletar e gerenciar dispositivos de roteamento/encaminhamento localizados no plano de dados, podendo afetar o tempo de processamento, resultando em sobrecarga do controlador e tempos de detecção mais longos. Uma alternativa é desenvolver soluções que atuem no plano de dados, reduzindo assim o tempo de detecção e a sobrecarga no controlador. Alguns trabalhos propuseram executar o processamento de detecção no plano de dados, mas se concentraram apenas no uso de métodos estatísticos, devido à complexidade de desenvolver soluções para atuar nessa camada [9, 10, 34]. Da mesma forma, as soluções state-of-the-art [8, 41, 45] mostraram o potencial dos algoritmos de ML para classificação de dados e seu uso na detecção de ataques DDoS. Até onde sabemos, os trabalhos na literatura consideram o uso de algoritmos de ML apenas no plano de controle. Além disso, é necessário propor métodos para reduzir os impactos causados por um ataque DDoS, considerando que a maioria das soluções apresentadas propôs ações para bloquear e descartar tráfego fraudulento, mas elas podem penalizar o tráfego legítimo, pois esse tipo de ataque pode simular o comportamento de tráfego legítimo, dificultando a diferenciação entre tráfego legítimo e fraudulento. O uso de métodos de reputação e priorização pode auxiliar nesse processo, permitindo que o tráfego legítimo seja atendido com mais eficiência, evitando que seja bloqueado.

A principal contribuição deste trabalho, como será apresentado na próxima seção, é superar essas limitações. Mais precisamente, propomos um mecanismo de detecção de ataques baseado em ML que funciona no plano de dados e engloba um mecanismo de reputação para evitar o bloqueio de tráfego legítimo, reduzindo assim os impactos causados por um ataque DDoS.

4. CONEXÕES BASEADAS EM REPUTAÇÃO

Esta subseção apresenta o algoritmo EigenTrust, que será usado posteriormente no DataPlane-ML para reduzir os efeitos de um ataque DDoS em uma infraestrutura SDN [48]. A reputação de um nó, ou confiança, tem sido usada no contexto de redes P2P para estimular nós a compartilhar seus recursos. Ou seja, nós com maior reputação recebem maior prioridade para certos serviços, como downloads mais rápidos e outros benefícios. O EigenTrust, proposto por Kamvar et al. [48], é um algoritmo de reputação para calcular a confiança em sistemas de compartilhamento de arquivos. Cada nó avalia as interações com outros nós para estabelecer um nível de confiança. Seja N o conjunto de nós em uma rede de comunicação. O EigenTrust usa a noção de confiança transitiva, onde um nó ni∈N que confia em um nó nj∈N também confiará nos nós que nj confia.

No contexto deste trabalho, quando um nó conclui com sucesso uma conexão TCP, a transação é classificada como satisfatória, o que gerará um impacto positivo de confiança para o nó que emitiu a solicitação. Para conexões falhas, ou seja, aquelas em que o nó que emitiu a solicitação não conseguiu concluir a conexão, a transação é classificada como insatisfatória, o que gerará um impacto negativo para o nó. O cálculo da confiança é realizado com base no sucesso e nas falhas das conexões, conforme a seguir:

Si,j=sati,j−unsati,j,

onde sati,jsati,j​ é o número de conexões bem-sucedidas emitidas pelo nó ni e recebidas pelo nó nj, e unsati,j é o número de tentativas de conexão malsucedidas do nó ni para o nó nj.

Os valores de confiança locais são agregados, normalizados e calculados de acordo com a reputação de outros nós. Os valores de confiança obtidos pelo EigenTrust não estão contidos em nenhum intervalo definido, ou seja, cada nó pode usar intervalos distintos para atribuir notas a cada serviço. No entanto, para otimizar o desempenho das comparações entre reputações, o EigenTrust realiza uma normalização para o valor de confiança local. Dessa forma, garante-se que todos os valores de confiança local estarão entre 0 e 1. Assim, para cada nó ni∈N, o valor de confiança local normalizado (Cij) é definido como:

Ci,j = {max⁡(Sij,0)/∑jmax⁡(Sij,0)   se ∑jmax⁡(Sij,0)≠0,
       {1/∣P∣                     caso contrario.

Na Eq. (2), se ∑jmax⁡(Sij,0)=0, Cij​ será indefinido pelo algoritmo. Para simplificar, consideramos a existência de uma noção prévia de confiança. Outros casos são discutidos em detalhes em Kamvar et al. [48]. Seja P, (P⊂N), um subconjunto de nós confiáveis. Então, um nó nini​ pode definir Cij=1/∣P∣ como seu valor de confiança local. Observe que P pode ser obtido trocando informações de confiança com outros nós. Uma vez que a confiança local para cada nó nini​ é obtida, um valor de confiança global pode ser calculado. Os valores locais normalizados são agregados com outros valores de confiança para aumentar o conhecimento sobre os nós que participam da rede. O valor de confiança global (Tci) de um nó ni é obtido somando o produto do valor de confiança local do nó (Cij) e o valor de confiança global correspondente dos outros nós (Tcj), definido como:

Tci=∑jCi,jTcj.

O valor de confiança global de um nó é obtido a partir das referências coletadas de outros participantes e ponderado com sua própria reputação. Essa característica tem o objetivo de limitar a influência de informações falsas de reputação que poderiam ser enviadas por nós maliciosos, geralmente com baixa reputação.

O algoritmo EigenTrust foi proposto no contexto de redes peer-to-peer, onde os papéis de cliente e servidor mudam ao longo do tempo. Ou seja, um nó ni pode ser o servidor de um arquivo F que está sendo baixado por outros clientes (peers). Da mesma forma, ni poderia ser um cliente baixando arquivos de outros servidores (peers). Neste trabalho, consideramos uma arquitetura cliente-servidor SDN, onde os papéis dos clientes e servidores são bem definidos. Mais precisamente, neste trabalho, estamos interessados em estabelecer a reputação dos clientes com base em seus padrões de conectividade para uma rede de destino que compreende alguns servidores. O objetivo é determinar a reputação dos clientes, com base nos padrões de conectividade, e posteriormente classificá-los de acordo com seus valores de confiança. Assim, no contexto SDN, o conjunto de hosts NN inclui o conjunto de nós clientes n=n0,n1,n2⋯ ,ni,i≥0 e o conjunto de servidores h=h0,h1,⋯ ,hj,j≥0. Ou seja, N=n∪h. Para referência futura, definimos a confiança global média dos clientes n, no contexto SDN, como:

Tα=1n∑i=1nTci.

Mais precisamente, Tα será usado como um limite para determinar se a confiança global Tci de um nó ni é alta o suficiente para ser confiável por um switch sj que está processando as solicitações de conexão de ni.

5. DATAPLANE-ML

Esta seção apresenta o DataPlane-ML, uma solução integrada para detectar e mitigar ataques DDoS em SDN. O DataPlane-ML usa técnicas de aprendizado de máquina (ML) para detecção e mecanismos de reputação de tráfego para evitar o bloqueio de tráfego legítimo e, assim, reduzir os impactos causados por ataques de SYN Flood. O principal desafio abordado pelo DataPlane-ML é executar os algoritmos de ML e reputação no plano de dados, sem impor uma sobrecarga adicional ao controlador SDN.

5.1 Visão Geral da Detecção e Mitigação de Ataques

O DataPlane-ML compreende dois módulos principais: o módulo de detecção e o módulo de mitigação. O primeiro módulo analisa e coleta informações estatísticas para identificar ameaças à rede. Em caso de um ataque à rede, o módulo de mitigação é usado para aliviar os efeitos do ataque, permitindo que nós confiáveis acessem os recursos da rede. Esses módulos são ilustrados na Figura 2. O módulo de detecção consiste em dois submódulos: o submódulo de aquisição de dados e o submódulo de detecção de ataques. A aquisição de dados e o cálculo de estatísticas são realizados pelos switches do plano de dados SDN. Neste trabalho, os switches do plano de dados são assumidos como incorporando a linguagem P4 para processar os dados de entrada. Ou seja, o switch habilitado para P4 extrai informações de fluxo e calcula estatísticas a partir dos dados obtidos dos campos do cabeçalho do pacote. Lembre-se de que um fluxo é uma sequência de pacotes de um endereço de nó de origem para um nó de destino (ou nós). Ou seja, o destino pode ser um único nó ou até mesmo um grupo de multicast. Os dados coletados (fluxos) podem ser agrupados em blocos discretos wiwi​, i>0, que chamamos de "janela". Os dados coletados e as estatísticas correspondentes são então enviados ao submódulo de detecção de ataques. O DataPlane-ML aproveita o fato de que os switches do plano de dados SDN podem ser implementados em cima de switches de caixa branca, usando chips comerciais, para executar algoritmos de ML. O switch do plano de dados executa o framework Apache Thrift para conectar os módulos e permitir a comunicação entre diferentes processos via chamadas de procedimento remoto (RPC). O modelo de ML recebe o fluxo de dados do switch P4 e executa os algoritmos de ML para determinar se um fluxo está relacionado a um ataque ou não. Em caso de ataque, essa informação é enviada ao módulo de mitigação. O módulo de mitigação usa um método baseado em reputação para estabelecer prioridade para fluxos de entrada, atribuindo-os a diferentes listas de prioridade. Em caso de ataque, a SDN ainda pode fornecer serviços àqueles nós/fluxos que atendem a um determinado nível de confiança, por meio do gerenciamento de listas. O nível de confiança é calculado com base na interação nó/switch e nas listas de prioridade.

Os módulos de detecção e mitigação de ataques operam monitorando as conexões de entrada. O monitoramento de conexões, que faz parte do módulo de mitigação, classifica as conexões de entrada como bem-sucedidas ou mal-sucedidas. Essa informação é usada posteriormente para definir a reputação de cada nó, com base em suas interações ao longo do tempo. As conexões de entrada são agrupadas em fluxos, que são então armazenados em janelas de observação wi,i≥0. Como mencionado anteriormente, as janelas de observação podem ser definidas para conter um número específico de pacotes (janelas baseadas em fluxo) ou para armazenar pacotes em um intervalo de tempo (janelas baseadas em tempo). O módulo de detecção de ataques usa as informações armazenadas nas janelas de observação para identificar uma possível ameaça à rede. Em caso de ataque, a informação é repassada ao módulo de mitigação, que permite novas conexões apenas para aqueles nós que têm alta prioridade para acessar os recursos da rede. Essa estratégia permite que a rede tome ações para evitar que nós maliciosos acessem os recursos da rede, usando tanto estratégias proativas quanto reativas. A estratégia proativa é executada pelo módulo de mitigação, atuando sobre conexões individuais e categorizando os nós em diferentes listas de prioridade. Essas listas são monitoradas e, com base na interação do nó, promovem ou restringem o acesso dos nós aos recursos da rede. As ações reativas são tomadas pelo módulo de detecção de ataques em caso de ataque, como mencionado anteriormente. Os detalhes dos módulos de detecção e mitigação de ataques são apresentados a seguir.

5.2 Módulos de Detecção de Ataques

Esta subseção apresenta os módulos de detecção de ataques do DataPlane-ML. Esses módulos compreendem o submódulo de aquisição de dados e o submódulo de detecção de ataques, que são detalhados a seguir.

5.2.1 Submódulo de Aquisição de Dados

O submódulo de aquisição de dados analisa os fluxos e encaminha as estatísticas correspondentes para o submódulo de detecção de ataques. Portanto, a primeira tarefa desse submódulo é agrupar pacotes em fluxos, o que é realizado no switch P4, conforme mostrado na Figura 3. Para determinar o fluxo ao qual um pacote pertence, o DataPlane-ML considera uma tupla de 4 elementos composta pelos campos de endereço IP e porta de origem e destino. Primeiro, o switch P4 recebe os pacotes de entrada e os valida, extraindo informações do cabeçalho do pacote. Cada fluxo recebe um número de identificação único, registrado na variável flow_id. Pacotes de entrada de um fluxo existente têm suas estatísticas calculadas e registradas para esse fluxo, como flow_bytes, flow_duration e flow_packets. Essas informações são enviadas periodicamente para o módulo de detecção. Mais precisamente, os dados de entrada são agrupados em janelas de observação, onde cada janela contém informações de vários fluxos. Cada janela de observação wi,i≥0 pode ser definida por um número fixo de fluxos (janela baseada em fluxo) ou por um intervalo de tempo (janela baseada em tempo). No primeiro caso, as janelas observadas contêm o mesmo número de fluxos (ou seja, ∣wi∣=∣wj∣,0<i<j). No segundo caso, o número de fluxos pode ser ∣wi∣≠∣wj∣,0<i<j, pois o número de fluxos pode variar ao longo do tempo.

5.2.2 Submódulo de Detecção de Ataques

Este trabalho se concentra em algoritmos de aprendizado supervisionado que atuam sobre os dados de entrada (janela de observação) recebidos do submódulo de aquisição de dados. O fluxo do submódulo de detecção de ataques é mostrado na Figura 4. Os dados de tráfego de entrada para o submódulo de detecção de ataques contêm os atributos adquiridos no submódulo de aquisição de dados. Ao receber esses dados, que são uma coleção de fluxos e suas respectivas estatísticas agrupadas em janelas de observação, eles são encaminhados para a etapa de pré-processamento de dados. Nessa etapa, o formato dos dados é convertido para transformar dados nominais em atributos binários. Essa transformação é útil para executar o processo de normalização, com o objetivo de evitar atributos desbalanceados. Em seguida, o submódulo de detecção de ataques verifica se existe um modelo de classificação treinado. Se existir, a previsão é realizada de acordo com o algoritmo de ML especificado. Caso contrário, os dados passam pela etapa de preparação do conjunto de dados, que divide o conjunto de dados em treinamento e teste para realizar a previsão de dados de acordo com o algoritmo de ML definido, em que uma parte dos dados é usada para treinamento e outra para teste (geralmente na proporção de 70% para treinamento e 30% para teste). O treinamento e o teste são realizados em tráfego sintético, onde tanto o tráfego legítimo quanto o fraudulento são gerados (detalhados posteriormente na Seção 6). Os rótulos correspondentes para tráfego fraudulento e legítimo são fornecidos para o treinamento do modelo. Para a etapa de teste, os rótulos são removidos, para analisar o comportamento do modelo após a fase de treinamento. Os resultados do treinamento são usados para avaliar o comportamento do modelo. Após definir o algoritmo de ML, um procedimento de otimização é executado para buscar os melhores parâmetros de ML. Esses parâmetros são otimizados por meio de uma busca de validação cruzada, para evitar o overfitting do modelo, encontrando o melhor modelo de classificação. O objetivo é aumentar a confiabilidade e a precisão do classificador. Para atualizar um modelo de classificação treinado, o modelo anterior é removido, forçando um novo processo de treinamento. Essa atualização depende de vários fatores, incluindo a mudança nas características do tráfego da rede e a capacidade do modelo de detectar e mitigar ataques à rede. Portanto, o momento mais apropriado para atualizar o modelo pode variar de uma rede para outra. Embora seja interessante identificar um momento apropriado para atualizar o modelo, essa tarefa está fora do escopo deste trabalho.

O melhor modelo para os algoritmos de ML é usado para classificar o tráfego da rede em normal ou ataque. O resultado dessa classificação é enviado de volta ao switch P4 em tempo de execução, que pode agir para mitigar o ataque (discutido na seção subsequente). Observe que os procedimentos acima podem aproveitar os períodos de ociosidade do switch para realizar o treinamento e a otimização do modelo. Além disso, para explorar melhor os períodos de ociosidade do switch, o administrador da rede pode usar as informações das atualizações passadas como uma aproximação do tempo necessário para futuras atualizações.

5.3 Módulo de Mitigação

Como mencionado anteriormente, um ataque DDoS funciona esgotando os recursos da rede, de modo que o tráfego legítimo não possa ser atendido. Quando o submódulo de detecção de ataques relata um possível ataque, o módulo de mitigação atuará para reduzir os efeitos do ataque. Ou seja, o objetivo do módulo de mitigação é manter a conectividade com nós confiáveis, mesmo durante um ataque. Além disso, o módulo de mitigação atua de forma proativa, identificando comportamentos inadequados de nós e impondo limites e restrições a eles. Como será discutido a seguir, o módulo de mitigação identifica clientes confiáveis, de modo que as conexões desses nós possam ser priorizadas.

5.3.1 Visão Geral das Listas de Prioridade

Para cada nó, o DataPlane-ML monitora suas tentativas de estabelecer uma conexão TCP e usa quatro listas distintas para sua classificação. Um fluxo de um nó desconhecido, assim como fluxos de nós que não atingiram um determinado nível de confiança, são categorizados como não classificados. Esses nós são inseridos na lista não classificada (UL) e não têm prioridade ao serem manipulados pelo switch P4. Após o estabelecimento bem-sucedido de uma conexão TCP, um nó obtém um valor de confiança que permite que ele passe da UL para a lista cinza (GL). Posteriormente, dependendo de seu comportamento, ele pode ser promovido para a lista branca (WL) ou rebaixado para a lista negra (BL). Além disso, um nó pode perder seu status e ser rebaixado para a BL quando considerado suspeito, ou seja, após algumas tentativas de conexão malsucedidas. Adicionalmente, um nó na lista branca pode perder a confiança recebida e ser caracterizado como não classificado. Finalmente, um nó movido para a lista negra é temporariamente bloqueado por ti=Ψ tempo, onde Ψ≥0. Até que o temporizador ti para o nó ni expire, o switch P4 não processará uma solicitação desse nó. Uma vez que o tempo de bloqueio expire, o nó pode retornar à lista não classificada, e as solicitações correspondentes serão atendidas sem qualquer prioridade. A Figura 5 mostra a migração de nós entre as listas à medida que seu nível de confiança muda.

Claramente, o esquema de prioridade mencionado requer um limite de confiança para cada lista, bem como um nível de confiança para cada nó. O módulo de mitigação usa dois submódulos para abordar esses problemas. O submódulo de monitoramento de conexões é responsável por: (1) monitorar as tentativas de estabelecer conexões TCP e atualizar as estatísticas para cada nó, que são usadas no gerenciamento das listas de prioridade; (2) promover um nó da UL para a GL após uma conexão bem-sucedida, dando a oportunidade para nós bem-comportados alcançarem mais rapidamente uma lista de prioridade mais alta; (3) rebaixar um nó para a BL após algumas tentativas malsucedidas de estabelecer uma conexão TCP, o que é importante para bloquear um nó que não concluiu nenhuma conexão; e (4) desbloquear um nó na BL após o tempo de bloqueio expirar, dando a oportunidade de estabelecer novas conexões. Por outro lado, o submódulo de gerenciamento de listas de prioridade usa as estatísticas coletadas e o método de reputação mencionado para calcular um nível de confiança para cada nó nas listas de prioridade mais alta, ou seja, GL e WL. Esse submódulo também monitora as mudanças de prioridade dos nós e pode impor restrições a nós que têm um nível de confiança instável (ou seja, bloqueando temporariamente o nó, adicionando-o à BL).

5.3.2 Submódulo de Monitoramento de Conexões

O monitoramento de conexões registra e analisa solicitações de conexão de nós, classificando-as como sucesso (satisfatória) ou falha (insatisfatória). A classificação é realizada pelo switch P4, que monitora as flags TCP trocadas entre a origem (cliente) e o destino (servidor) durante o processo de handshake de três vias. Um timeout é estabelecido para cada solicitação TCP SYN, que é monitorado pelo switch P4. O timeout é definido com base em dados históricos (timeouts anteriores de conexão TCP), considerando um ambiente operando em condições normais. Dessa forma, um timeout adequado é estabelecido a partir do momento em que o switch P4 recebe a primeira solicitação TCP SYN até o primeiro ACK para concluir a conexão TCP. Conexões TCP bem-sucedidas geram um impacto positivo na reputação do nó. Por outro lado, conexões TCP malsucedidas têm um impacto negativo na reputação do nó. Seja γi​ o número de tentativas de conexão falhas emitidas pelo nó ni​. Se γi​ exceder um limite pré-definido Γ, a conexão é descartada, e o nó é adicionado à lista negra. Lembre-se de que os nós na lista negra são bloqueados por ti=Ψ tempo, onde Ψ≥0. Quando o temporizador expirar, o nó será removido da lista negra e adicionado à lista não classificada.

O Algoritmo 1 resume a discussão acima. Na primeira etapa, as estatísticas de cada conexão bem-sucedida são atualizadas, cujas conexões são classificadas como satisfatórias para cada nó pertencente às listas de prioridade (lista cinza ou lista branca). Se a conexão for classificada como malsucedida, o nó será adicionado à lista negra caso γi≥Γ e promovido para a UL quando o temporizador ti expirar.

Diferentemente do módulo de detecção de ataques, que opera em um conjunto de fluxos (janelas observadas), o algoritmo de monitoramento de conexões é acionado com base em solicitações de conexão TCP. Ou seja, o sucesso ou falha da conexão TCP de um nó determina se um nó pode ser promovido a uma lista de prioridade ou rebaixado para uma lista de baixa prioridade. Para isso, o Algoritmo 1 monitora as conexões TCP e age com base no sucesso ou falha de uma conexão.

Algoritmo 1: Monitoramento de Conexões para o nó nini​

    Passo 1: Após uma conexão TCP bem-sucedida do nó ni∈n, onde ni∉BL, faça:

        Passo 1.1: Promover: Se o nó ni∈UL, promova nini​ da UL para a GL;

        Passo 1.2: Atualizar: Se ni∈GL ou ni∈WL, atualize as estatísticas para o nó ni na lista correspondente (GL ou WL);

    Passo 2: Após uma conexão TCP malsucedida do nó ni, onde ni∈GL ou ni∈WL, faça:

        Passo 2.1: Conexão malsucedida: Se γi≥Γ, adicione nini​ à BL, defina γi=0 e remova ni da lista de prioridade (GL ou WL);

        Caso contrário, defina γi=γi+1;

    Passo 3: Se ni∈BL e o temporizador ti expirar, promova ni da BL para a UL.

5.3.3 Submódulo de Gerenciamento de Listas de Prioridade

O gerenciamento de listas de prioridade é responsável por lidar com os nós presentes nas listas de prioridade (GL ou WL). Um limite de confiança global é usado para avaliar a transição entre as listas (seja para elevar ou reduzir a prioridade de um nó). O limite de confiança global define a sensibilidade do mecanismo proposto. O limite de confiança global é um limite ponderado definido como:

Tg=α⋅Ta+(1−α)⋅Tg,

onde Ta é a confiança global média calculada pela Eq. (4) e TgTg​ é o limite de confiança global previamente calculado, e αα é um coeficiente de suavização. O coeficiente αα assume valores no intervalo (0≤α≤1). Um αα mais alto implica um peso maior em Ta, em contraste com os valores passados em Tg. Por outro lado, um valor mais baixo de αα implica um peso maior nos valores passados de Tg, em contraste com o valor médio atual de confiança Ta. Assim, o limite pode ser ajustado de acordo com as características da rede, bem como para atender às necessidades do administrador.

Para cada lista de prioridade (lista cinza ou lista branca), o limite de confiança global Tg​ é calculado. Assim, se a confiança global Td​ de um nó ni​ pertencente à lista cinza estiver acima do limite (Tg​), o nó nini​ será promovido para a lista branca. Por outro lado, se um nó pertencente a uma lista de prioridade tiver uma confiança global Td igual ou abaixo do limite Tg​, o nó será movido para a lista não classificada. O último evento é registrado em ni, que conta o número de remoções de ni​ das listas de prioridade. Se o nó exceder o número Δ de remoções permitidas da lista de prioridade, o nó será adicionado à lista negra, e o temporizador ti=Ψ será definido.

Os passos mencionados acima para o processamento das listas de prioridade são mostrados no Algoritmo 2. Observe que o algoritmo pode ser executado em intervalos irregulares. Ou seja, o Algoritmo 2 pode ser processado mesmo antes que uma janela de observação wiwi​, i≥0 seja concluída. Isso permite que o processamento das listas seja atualizado em um ritmo mais rápido ou mais lento, de acordo com as necessidades do administrador e da aplicação. Se a rede estiver sob ataque, o switch P4 prioriza nós na lista branca (WL) para serem atendidos, enquanto os nós na lista cinza (GL) só serão atendidos se não houver solicitações pendentes de um nó ni∈WL.

Algoritmo 2: Processamento das Listas

    Passo 1: Calcule o limite de confiança global Tg usando a Eq. (5).

    Passo 2: Para cada nó ni∈GL, se Tci>Tg, promova ni para a WL;

    Passo 3: Para cada nó ni, se Tci≤Tg, adicione ni à UL; remova-o da lista correspondente (GL ou WL) e incremente o contador de remoções ri=ri+1;

    Passo 4: Se ri≥Δ para o nó ni, remova o nó da lista de prioridade (GL ou WL) e adicione ni à BL, defina ti=Ψ e ri=0;

6. AVALIAÇÃO DE DESEMPENHO

Esta seção avalia o DataPlane-ML proposto. Começamos detalhando os parâmetros do ambiente experimental, a metodologia de avaliação e as métricas usadas para avaliar os resultados. Em seguida, os módulos de detecção de ataques do DataPlane-ML são avaliados usando um conjunto de algoritmos de ML. Finalmente, os módulos de mitigação e o comportamento das listas de prioridade são examinados.

6.1 Configuração e Metodologia de Avaliação

O DataPlane-ML é avaliado em duas fases: a primeira fase avalia o módulo de detecção de ataques com os algoritmos KNN, SVM e RF. Esses algoritmos foram selecionados porque são amplamente usados para classificação de dados, bem como para detectar ataques de rede. Os algoritmos são implementados no plano de dados usando as bibliotecas Scikit-Learn. A função RandomizedSearchCV foi usada para selecionar os melhores hiperparâmetros para treinar e ajustar o modelo de detecção usando validação cruzada k-fold, listados na Tabela 1. A entropia, que é um método de detecção de ataques baseado em estatísticas, foi selecionada para fins de comparação. As seguintes métricas serão usadas para avaliar a fase de detecção de ataques:

    Uso da CPU na validação cruzada: mede o uso da CPU no switch durante a execução do processo de validação cruzada, bem como o uso da CPU para detectar um ataque;

    Tempo de computação da validação cruzada: tempo gasto para calcular a validação cruzada;

    Acurácia: indica a porcentagem de pacotes (legítimos ou fraudulentos) que o modelo classificou corretamente durante o ataque;

    Tempo de detecção: tempo decorrido entre o início do ataque de SYN Flood e sua detecção;

    Tamanho da janela: número de pacotes presentes na janela de observação durante a fase de detecção de ataques.

A segunda fase refere-se ao processo de mitigação, em que os algoritmos de monitoramento de conexões e reputação são usados. Lembre-se de que o monitoramento de conexões (Algoritmo 1) avalia o sucesso das conexões TCP, enquanto o Algoritmo 2 calcula a confiança global média do nó para estabelecer a prioridade do nó. As seguintes métricas serão usadas para avaliar a fase de mitigação:

    Uso da CPU: mede o uso da CPU no switch para executar o algoritmo de reputação usando diferentes coeficientes de suavização;

    Tempo de cálculo da confiança local: indica o tempo que a solução gasta para calcular o valor de confiança local dos nós;

    Variabilidade do valor de confiança global: indica a variabilidade do valor de confiança global com a variação da porcentagem de ocupação da janela de observação. Dada uma janela de observação ∣wi∣=f fluxos, a porcentagem de ocupação da janela de observação é definida como f⋅x, onde (0≤x≤1);

    Variação do coeficiente de suavização das listas de prioridade: indica o impacto do coeficiente de suavização no cálculo do limite de confiança global;

    Número de pacotes presentes nas listas de acordo com o coeficiente de suavização: número de pacotes presentes no switch de acordo com o coeficiente de suavização aplicado;

    Acurácia: indica a porcentagem de pacotes (legítimos ou fraudulentos) que o modelo classificou corretamente.

Os algoritmos do DataPlane-ML usam vários parâmetros, que podem ser ajustados para otimizar seu desempenho. A Tabela 1 lista os parâmetros usados nos experimentos, detalhados nas subseções 6.2 e 6.3. O emulador de rede Mininet é usado para fornecer o ambiente SDN, que é usado em ambas as fases (detecção de ataques e mitigação). Os experimentos foram realizados em um computador com processador i7, 3.0 GHz e 8 GB de RAM, rodando Ubuntu 16.04 LTS. A topologia SDN consiste em 4 switches gerenciados por um único controlador e 10 hosts (9 clientes e 1 servidor). A rede está conectada a outras redes por meio de um gateway, a partir do qual pode se comunicar com outras redes e dispositivos, conforme mostrado na Figura 6.

A largura de banda de cada link é definida como 100 Mbps. Lembre-se de que os algoritmos do DataPlane-ML para detecção e mitigação de ataques são implementados no plano de dados. Portanto, o DataPlane-ML é implementado nos switches SDN (S1 a S4​). Nos experimentos, presume-se que o atacante tenha obtido controle de um host legítimo (n9) para realizar o ataque (SYN Flood), que está conectado ao switch S4. Observe que o ataque poderia ter sido direcionado de uma fonte externa. Em ambos os casos, o tráfego fraudulento passará pelos dispositivos de encaminhamento/roteamento onde o DataPlane-ML está em execução. A vítima (h0) é um servidor web responsável por lidar com solicitações HTTP, conectado ao switch S2. O tráfego legítimo e fraudulento são gerados sinteticamente usando a ferramenta Scapy. O tráfego legítimo tem uma taxa de 10 solicitações HTTPS por segundo, enquanto o tráfego fraudulento tem uma taxa de 100 solicitações HTTP por segundo. Os experimentos são executados por 30 segundos. O tráfego fraudulento é injetado por 9 segundos (tempo experimental de 13s a 22s). Os resultados são calculados como a média de 5 execuções experimentais.

6.2 Resultados da Detecção de Ataques

Esta seção relata os resultados experimentais para a fase de detecção de ataques usando as métricas discutidas na subseção anterior. Começamos avaliando os custos computacionais do treinamento de ML. Em seguida, discutimos o uso da CPU, a acurácia e o tempo de detecção de ataques, considerando um cenário em que o atacante envia numerosos pacotes SYN com endereços IP falsificados para o servidor.

A Figura 7 apresenta o uso da CPU na validação cruzada (7a e 7b) e o tempo de computação da validação cruzada (7c e 7d) para cada algoritmo de ML. A figura mostra os resultados para janelas baseadas em tempo e janelas baseadas em fluxo. Os resultados mostram que o uso da CPU e o tempo de computação da validação cruzada aumentam com o número de fluxos na janela de observação. Janelas maiores têm mais dados a serem processados, impactando suavemente essas métricas. Por exemplo, uma janela de observação com 125 fluxos demanda 40% de uso da CPU com o algoritmo KNN, enquanto uma janela de observação com 200 fluxos aumenta o uso da CPU em no máximo 5%. O uso da CPU e o tempo de computação são maiores para janelas baseadas em tempo, pois podem conter mais dados do que janelas baseadas em fluxo (discutido posteriormente).

As diferenças de complexidade dos algoritmos de ML são perceptíveis nos resultados experimentais. Entre os algoritmos de ML, o RF é o mais caro, tanto em termos de tempo de computação quanto de uso da CPU, devido ao número de subconjuntos para buscar a melhor divisão de um nó (max_features), o número de árvores criadas na floresta (n_estimators), o processamento de diferentes árvores de acordo com o nível de profundidade estabelecido (max_depth), o número de amostras necessárias para dividir um nó interno (min_samples_split) e o número mínimo de amostras necessárias para estar em um nó folha (min_samples_leaf). Entre esses parâmetros, n_estimators e max_depth são os que têm o maior impacto no modelo. Os parâmetros de ML para cada algoritmo de ML estão listados na Tabela 1. Diferentes algoritmos de SVM podem usar funções de kernel distintas, incluindo linear, polinomial, função de base radial (RBF) e sigmoide. Em particular, a função de kernel RBF tem sido amplamente usada devido à sua capacidade de aprendizado e aplicabilidade tanto em espaços de baixa quanto de alta dimensionalidade, bem como em amostras pequenas e grandes. Neste trabalho, a função de kernel RBF é usada. O kernel RBF requer a otimização de um parâmetro real Gamma > 0, que define até onde a influência de um único exemplo de treinamento alcança. Quanto maior o Gamma, mais próximos os outros exemplos devem estar para serem afetados. Da mesma forma que o Gamma, o parâmetro C deve ser escolhido com cuidado, pois ele equilibra exemplos de treinamento contra a simplicidade da superfície de decisão. Finalmente, o KNN apresentou o menor uso da CPU e tempo de computação na validação cruzada, conforme mostrado na Figura 7. Os custos reduzidos do KNN são devidos a: (i) baixa complexidade na busca pelos pontos vizinhos mais próximos, e (ii) ao número reduzido de atributos usados para definir o melhor modelo de classificação. Os atributos do KNN avaliados são o número de vizinhos n_neighbors e seu peso. Neste trabalho, os parâmetros de peso otimizados usaram tanto o uniforme, que usa o mesmo peso para todos os vizinhos, quanto a distância Euclidiana, que atribui pesos maiores aos vizinhos mais próximos. Considerando janelas de observação baseadas em fluxo, o KNN requer, em média, 13% e 27% menos CPU do que SVM e RF, respectivamente. Já nas janelas de observação baseadas em tempo, o KNN requer, em média, 10% e 23% menos CPU do que SVM e RF, respectivamente. Em termos de tempo de computação, considerando janelas baseadas em fluxo, o algoritmo KNN foi, em média, 28% e 47% mais rápido do que SVM e RF, respectivamente. Considerando janelas baseadas em tempo, o algoritmo KNN foi, em média, 24% e 41% mais rápido do que SVM e RF, respectivamente.

Uma vez que o modelo é treinado, o próximo passo é avaliar a acurácia do modelo para detectar um ataque. Métodos baseados em entropia são comumente usados para detectar anomalias no tráfego da rede. Portanto, a entropia será usada para comparar a acurácia dos algoritmos de ML. Lembre-se de que o experimento dura cerca de 30 segundos, e o ataque de SYN Flood começa 13 segundos após o início dos experimentos, durando cerca de 9 segundos. A Figura 8 mostra a acurácia (8a e 8b), o uso da CPU (8c e 8d) e o tempo de detecção de ataques (8e e 8f) para KNN, SVM, RF e entropia. Em janelas baseadas em fluxo, houve um aumento gradual na acurácia, no consumo de CPU e no tempo de detecção à medida que o número de fluxos em uma janela aumenta. Por outro lado, a acurácia das janelas baseadas em tempo diminui cerca de 0,77% quando o tempo da janela aumenta de 0,5s para 2,0s. Curiosamente, com um aumento substancial no número de fluxos em janelas baseadas em tempo, a acurácia dos algoritmos de ML diminui. Essa degradação foi causada por uma forte dispersão nos dados, dificultando sua separação, resultando em uma acurácia menor pelos algoritmos de ML. A entropia, por outro lado, é capaz de explorar melhor o aumento do número de fluxos em janelas baseadas em tempo para melhorar a acurácia. No geral, os algoritmos de ML superaram o método de detecção de ataques baseado em entropia, com acurácia entre 97% e 98,5% nas configurações avaliadas.

Conforme mostrado nas Figuras 8c e 8d, as demandas de CPU para detecção de ataques foram de cerca de 25% a 30%. Assim como nos resultados de treinamento, o RF ainda demanda mais CPU em comparação com KNN, SVM e entropia. Por outro lado, o algoritmo RF supera KNN, SVM e entropia, mostrando um aumento de 0,85% na acurácia de detecção, pois é capaz de realizar uma melhor correlação entre os atributos e as árvores criadas. No entanto, ele tem um custo computacional maior do que os outros, usando em média até 28% dos recursos da CPU, enquanto SVM e KNN usaram, em média, 26,2% e 23,3%, respectivamente. Em geral, a entropia consumiu ≈13% mais CPU do que o KNN devido à sua análise de probabilidade, que requer mais tempo para coletar e analisar dados. Finalmente, em janelas baseadas em tempo, os algoritmos são ≈16% mais lentos para detectar um ataque em comparação com janelas baseadas em fluxo, pois retêm um número maior de fluxos. O algoritmo KNN foi ≈10% mais rápido do que os outros, devido à baixa complexidade na busca pelos vizinhos mais próximos. A entropia foi o algoritmo que levou mais tempo para detectar qualquer mudança na rede. Em comparação com a detecção baseada em entropia, as técnicas de ML foram, em média, 26% mais rápidas. O motivo desse comportamento é que a entropia precisa calcular frequências observadas para calcular os valores de entropia, uma vez que não realiza o processo de treinamento e teste para definir o melhor modelo de classificação.

O número de pacotes presentes em janelas baseadas em tempo e janelas baseadas em fluxo quando um ataque é detectado pode ser visto na Figura 9. Em ataques de SYN Flood, os fluxos fraudulentos contêm 2 pacotes, ou seja, o TCP SYN enviado pelo atacante e um TCP SYN-ACK enviado pelo servidor como resposta. Por outro lado, as solicitações HTTP legítimas contêm vários pacotes (por exemplo, estabelecimento de conexão TCP, solicitação e resposta HTTP, encerramento da conexão TCP). Portanto, o número de pacotes em cada fluxo varia, como pode ser observado na Figura 9. Durante um ataque, o número de pacotes presentes em janelas baseadas em tempo (9b) é, em média, 135% maior do que o número de pacotes em janelas baseadas em fluxo (9a). Essa diferença impacta o tempo de detecção, o uso de recursos e a acurácia da detecção. Em resumo, a escolha do tipo e do tamanho da janela deve levar em consideração o volume do ataque e a dispersão dos dados. A escolha correta desses parâmetros pode levar a uma melhor acurácia, menor consumo de recursos e detecção mais rápida de ataques.

6.3 Resultados da Mitigação

Esta seção relata os resultados experimentais para a fase de mitigação. Primeiro, avaliamos o impacto da variabilidade do tamanho da janela na reputação dos nós, incluindo os custos computacionais para obter o valor de confiança local (Cij) e os limites de confiança global (Tci). Em seguida, discutimos o impacto do coeficiente de suavização (α) na definição do limite de confiança global (Tg) usado para estabelecer a prioridade dos nós.

A fase de detecção de ataques requer uma quantidade considerável de informações para detectar mudanças no comportamento dos nós. A reputação dos nós, por outro lado, pode ser calculada com base nas conexões dos nós. No entanto, calcular a reputação dos nós com base em conexões pode impor uma sobrecarga maior nos switches P4. Como alternativa, consideramos calcular a reputação dos nós com base em informações parciais da janela de observação. A Figura 10a mostra o tempo médio para calcular o valor de confiança local (Cij) com diferentes porcentagens de ocupação da janela de observação. A confiança local (Eq. 2) é calculada usando quatro diferentes porcentagens de ocupação da janela de observação: 25%, 50%, 75% e 100%. Aqui, consideramos uma janela baseada em fluxo, que tem um tamanho de 150 fluxos. A figura mostra que o tempo de cálculo da confiança local aumenta linearmente com a porcentagem de ocupação da janela de observação. Com uma janela de observação wiwi​, i≥0 definida como 25% (≈38 fluxos), o tempo de cálculo leva cerca de 30 ms, enquanto uma janela completa (wiwi​ com 150 fluxos) leva 120 ms. Um sistema de reputação mais conservador pode exigir que a confiança local seja calculada em intervalos mais curtos. Isso, por sua vez, aceleraria as mudanças na reputação dos nós e nas listas de prioridade. A Figura 10b mostra o uso da CPU para calcular a confiança local com diferentes porcentagens de ocupação da janela de observação. Ao executar o algoritmo em uma ocupação de 25% da janela, o processo é repetido 4 vezes para atingir 100%, totalizando 24,5% de consumo de CPU, gerando um aumento de 21% em comparação com uma janela de 100%. Assim, o uso da CPU é ligeiramente maior com porcentagens menores de ocupação da janela.

O valor de confiança local é usado para calcular a confiança global do nó Tci, definido na Eq. (3), que é então usado para atribuí-lo à lista de prioridade correspondente de acordo com as regras do Algoritmo 2. O valor Tci é diretamente influenciado pela ocupação da janela de observação, como pode ser observado na Figura 11. À medida que a ocupação da janela de observação aumenta, a variação nos valores de confiança global diminui. O valor de confiança global é de cerca de 0,6715 quando w é definido como 25% e cerca de 0,6048 quando w é definido como 100%. A maior variabilidade na confiança global dos nós, por sua vez, impacta as listas de prioridade, impondo custos mais altos para o gerenciamento das listas.

O impacto do coeficiente de suavização (α) na definição do limite de confiança global (Tg) é discutido a seguir. Nos experimentos, αα assume os seguintes valores: 0,1, 0,5 e 0,9. A ocupação da janela de observação (ω) foi definida como 75% (≈113 fluxos), e o algoritmo de detecção KNN foi usado. O tempo total de simulação foi definido como 30 segundos, onde o ataque de SYN Flood começa após 13 segundos do início da simulação, durando 9 segundos. A Figura 12a mostra as mudanças no limite de confiança global ao longo do tempo experimental de 30 segundos. O limite é calculado de acordo com a Eq. 5. Observe que, nos momentos iniciais, o limite de confiança global (Tg) expressa valores semelhantes, independentemente do coeficiente usado. À medida que a simulação avança, a influência do coeficiente no limite de confiança global torna-se perceptível. A partir do momento em que a confiança local é obtida, é possível observar as variações no limite global. Quando um coeficiente de suavização mais baixo (α) é usado, o limite global tende a ser mais estável, pois as informações passadas têm um peso maior. Por outro lado, atribuir um valor maior ao coeficiente de suavização (α) faz com que o limite reaja à atividade recente do nó, comportamento observado para o coeficiente α=0,9. O coeficiente de suavização impacta o gerenciamento das listas de prioridade, refletindo no uso da CPU, como pode ser observado na Figura 12b. Por exemplo, para um coeficiente α=0,9, há um aumento no uso da CPU de cerca de 8% em comparação com o coeficiente 0,1. Portanto, é necessário observar esses aspectos ao escolher o coeficiente de suavização para o limite de confiança global das listas de prioridade.

Em seguida, avaliamos o coeficiente de suavização e seu impacto no comportamento das listas de prioridade. Lembre-se de que o DataPlane-ML é implementado nos switches SDN (S1​ a S4). O atacante é assumido como tendo controle de um host legítimo (n9) para realizar o ataque (SYN Flood), que está conectado ao switch S4. Para cada segundo, registramos o número de pacotes manipulados pelo switch S4 e a lista de prioridade à qual o nó remetente pertence naquele momento. A Figura 13 mostra o número de pacotes manipulados pelo switch S4 e a lista correspondente à qual os nós remetentes estão associados naquele momento. Observe que o número de pacotes para cada lista varia, pois as solicitações HTTP podem conter vários segmentos TCP (estabelecimento de conexão TCP, solicitação, resposta, término e retransmissão). O atacante, nos momentos iniciais (1s - 12s), tem um comportamento semelhante aos nós legítimos, o que permite que ele entre nas listas de prioridade e, consequentemente, acesse a lista de prioridade mais alta (lista branca). À medida que os nós são promovidos para a lista branca, a porcentagem de pacotes de nós da lista cinza diminui. Esse comportamento é evidente na figura, no tempo experimental de 2 a 4 segundos, independentemente do valor do coeficiente de suavização. Observe que o ataque começa no tempo 13 segundos, momento em que há um aumento abrupto no número de pacotes na lista branca. Esse comportamento se refere ao grande volume de solicitações SYN recebidas pelo switch S4 em um curto espaço de tempo. À medida que o número de tentativas de conexão falhas permitidas (Γ) é excedido, o nó suspeito é removido da lista de prioridade (WL ou GL), adicionado à lista negra e permanece lá por Ψ tempo de bloqueio. Isso, por sua vez, causa um aumento nos pacotes na lista negra, como pode ser observado na figura, no tempo experimental de 14 a 17 segundos. Um coeficiente de suavização mais baixo atrasa as mudanças nas listas de prioridade, pois o limite atribui um peso maior às informações passadas. Por exemplo, com α=0,1, o nó suspeito é bloqueado no tempo 17s, ou seja, 4s após o início do ataque. Por outro lado, com α=0,9, o nó suspeito é bloqueado no tempo 15s, ou seja, 2s após o início do ataque. Portanto, definir α para valores mais altos permite que os algoritmos de mitigação bloqueiem nós suspeitos mais rapidamente. No entanto, isso tem um impacto no uso da CPU, como discutido anteriormente. Uma vez que o ataque é detectado, o número de pacotes de fontes da lista negra continua a aumentar, enquanto a lista branca e a lista cinza retornam a valores semelhantes aos anteriores ao ataque, alguns segundos depois. Ou seja, o DataPlane-ML bloqueou o nó suspeito e permitiu que nós confiáveis continuassem se comunicando com o servidor de destino.

A acurácia do mecanismo de mitigação é mostrada na Figura 14 para os seguintes intervalos: antes do ataque (1s-12s), durante o ataque (13s-22s) e após o ataque (23s-30s). A acurácia é calculada para diferentes valores do coeficiente de suavização (α). Diferentes valores de α podem afetar a acurácia, como pode ser observado mesmo para intervalos em que não há presença de pacotes fraudulentos. Assim, um valor maior para o coeficiente promove um grande número de remoções de nós das listas, devido ao peso dado às informações mais recentes, o que pode levar ao bloqueio de um nó legítimo se ele exceder o número de remoções permitidas para as listas (Δ), impactando a acurácia do mecanismo. Por exemplo, para o coeficiente α=0,9, há uma redução média de 2% na precisão em comparação com o coeficiente α=0,1, considerando os intervalos (antes e após o ataque). Observe que há uma redução de 3% na acurácia durante o ataque em comparação com o intervalo antes do ataque. Essa redução está relacionada ao volume de pacotes presentes nas listas de prioridade, juntamente com o coeficiente aplicado e o número de remoções dos nós das listas. Observe que, após o ataque, a precisão aumenta, ficando semelhante à antes do ataque. O motivo desse aumento é que os nós na lista negra são eventualmente desbloqueados. Observe que a lista negra poderia impor uma penalidade mais severa para nós maliciosos recorrentes, de modo que esses nós seriam bloqueados permanentemente. No geral, a acurácia do mecanismo é superior a 95% para o intervalo experimental (1s-30s). O nível de acurácia obtido mostra que o mecanismo de mitigação proposto é eficiente para bloquear tráfego fraudulento enquanto mantém a conectividade dos nós legítimos.

7. CONCLUSÃO

Este artigo apresentou e analisou o DataPlane-ML, uma solução para detectar e mitigar ataques de SYN Flood em Redes Definidas por Software (SDN). O DataPlane-ML, como o nome sugere, opera no plano de dados da SDN e usa métodos baseados em aprendizado de máquina (ML) para detectar desvios no comportamento do tráfego que podem caracterizar um ataque. Além disso, o DataPlane-ML engloba um algoritmo de reputação para estabelecer confiança entre nós, permitindo a identificação e a restrição de nós maliciosos no acesso aos recursos da rede. Nos cenários avaliados, e em comparação com mecanismos de detecção de ataques baseados em estatísticas, o DataPlane-ML forneceu uma acurácia superior a 98%, enquanto exigiu ≈15% menos tempo de processamento da CPU. A mitigação do DataPlane-ML usa um mecanismo de reputação para identificar e recompensar nós confiáveis. Nós cujo comportamento é considerado inadequado ou suspeito são movidos para listas de baixa prioridade e podem ser temporariamente bloqueados. O mecanismo de reputação usa um coeficiente de suavização que pode ser ajustado para atender às necessidades da rede e das aplicações. Nos cenários avaliados, a estratégia de mitigação do DataPlane-ML conseguiu preservar o tráfego legítimo, alcançando uma acurácia média de 95%. Os resultados acima mostram que o DataPlane-ML proposto pode melhorar a acurácia na detecção de ataques sem impor uma carga maior no switch P4. Além disso, como o DataPlane-ML funciona no plano de dados, não há necessidade de comunicação adicional entre o controlador e o switch, reduzindo assim o atraso para tomar as ações adequadas. Em trabalhos futuros, planejamos melhorar o DataPlane-ML para detectar outros tipos de ataques e avaliar o tempo necessário para atualizar os modelos para os parâmetros usados neste trabalho.

